{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "763007a1-1231-4db7-ba61-db0825a9fbca",
   "metadata": {},
   "source": [
    "# General Preprocessing: union of different approaches after exploration\n",
    "\n",
    "Until 13/09/2021 I save the feature extraction for 22KHz and 48 KHz, by using 12 and 40 mel spectrograms and other features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "616c6813-b3f3-411f-84d8-71c89c3e07b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio Library\n",
    "import librosa\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "# Handling Paths\n",
    "import os\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "# Time\n",
    "import time\n",
    "# sklearn\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60f3718-5451-433c-a426-d37c39ccf1f5",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2653bc99-114e-4681-b1f7-5c035dc35d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/src\n",
      "Number of total audios: \n",
      "1440\n",
      "Name Example: \n",
      "03-01-04-01-01-01-01.wav\n"
     ]
    }
   ],
   "source": [
    "root_path = os.getcwd()\n",
    "print(root_path)\n",
    "\n",
    "data_path = '../data'\n",
    "\n",
    "def calling_audios(data_path):\n",
    "    '''\n",
    "        Saving audio names\n",
    "    '''\n",
    "    names = list()\n",
    "    for dirname, _, filenames in os.walk(root_path + data_path):\n",
    "        for filename in filenames:\n",
    "            names.append(filename)\n",
    "    return names\n",
    "\n",
    "audio_names = calling_audios(data_path)\n",
    "\n",
    "# Audio Numbers\n",
    "print(\"Number of total audios: \")\n",
    "print(len(audio_names))\n",
    "\n",
    "print(\"Name Example: \")\n",
    "print(audio_names[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea4bda55-4f65-4f9f-b25b-300b0f3e49eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Audio_Energy(x):\n",
    "    hop_length = 256\n",
    "    frame_length = 512\n",
    "    return librosa.feature.rms(x, frame_length=frame_length, hop_length=hop_length, center=True)\n",
    "\n",
    "def Zero_Crossing(x):\n",
    "    return librosa.feature.zero_crossing_rate(x)\n",
    "\n",
    "def Spectral_Centroids(x,sr):\n",
    "    return librosa.feature.spectral_centroid(x, sr=sr)[0]\n",
    "\n",
    "def normalize(x, axis=0):\n",
    "    return sklearn.preprocessing.minmax_scale(x, axis=axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e464c0f-ec73-4482-888a-bdeeff0b808c",
   "metadata": {},
   "source": [
    "### Preprocessing without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9ecc747-ba39-4219-ae4c-c9d27f7d7f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_info_table(path,sample_rate = 48000):\n",
    "    big_model = []\n",
    "    small_model = []\n",
    "    big_model_log = []\n",
    "    small_model_log = []\n",
    "    audio_lengths = []\n",
    "    wave_forms = []\n",
    "    lst = []\n",
    "    \n",
    "    epsilon = 0.01\n",
    "    \n",
    "    start_time = time.time()\n",
    "    count = 0\n",
    "    for subdir, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            count += 1\n",
    "            try:\n",
    "                ##Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
    "                X, sample_rate = librosa.load(os.path.join(subdir,file),sr=sample_rate,duration=3, offset=0.5,res_type='kaiser_fast')\n",
    "                \n",
    "                \n",
    "                # make sure waveform vectors are homogenous by defining explicitly\n",
    "                waveform_homo = np.zeros((int(sample_rate*3,)))\n",
    "                waveform_homo[:len(X)] = X\n",
    "                \n",
    "                # Model 1 (big)\n",
    "                mfccs = np.mean(librosa.feature.mfcc(y=waveform_homo, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
    "                # Model 2 (small)\n",
    "                mfccs_small = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=12).T,axis=0) \n",
    "\n",
    "                # Model 1 (big log) \n",
    "                mfccs_log = np.mean(librosa.power_to_db(librosa.feature.mfcc(y=waveform_homo, sr=sample_rate, n_mfcc=40).T),axis=0) \n",
    "\n",
    "                # Model 2 (small log) \n",
    "                mfccs_small_log = np.mean(librosa.power_to_db(librosa.feature.mfcc(y=waveform_homo, sr=sample_rate, n_mfcc=12).T),axis=0) \n",
    "\n",
    "                \n",
    "                energy = Audio_Energy(waveform_homo)\n",
    "                zero_cross =  Zero_Crossing(waveform_homo+epsilon)\n",
    "                spectral_centroids = Spectral_Centroids(waveform_homo+epsilon,sample_rate)\n",
    "                \n",
    "                # La lista tiene 3 vectores de caracteristicas por elemento\n",
    "                arr = energy, zero_cross, spectral_centroids\n",
    "                lst.append(arr)\n",
    "                \n",
    "                \n",
    "                ## The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
    "                ## This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
    "                file = int(file.split(\"-\")[2])\n",
    "                \n",
    "                arr = mfccs, file\n",
    "                arr_small = mfccs_small, file\n",
    "                arr_log = mfccs_log, file\n",
    "                arr_small_log = mfccs_small_log, file\n",
    "                \n",
    "                big_model.append(arr)\n",
    "                big_model_log.append(arr_log)\n",
    "                small_model.append(arr_small)\n",
    "                small_model_log.append(arr_small_log)\n",
    "                \n",
    "                audio_lengths.append(len(waveform_homo))\n",
    "                wave_forms.append(waveform_homo)\n",
    "                \n",
    "          # If the file is not valid, skip it\n",
    "            except ValueError:\n",
    "                continue\n",
    "    print(\"Total Number of Audio Files\")\n",
    "    print(count)\n",
    "    print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    return big_model, small_model, big_model_log,small_model_log,audio_lengths,wave_forms, lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db949607-a9df-492c-9acc-257ab67f7087",
   "metadata": {},
   "source": [
    "### Augmentation by using the waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daec4a9f-4e74-4fd7-86c6-2ffb5f429c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAVDESS native sample rate is 48k\n",
    "sample_rate = 48000\n",
    "\n",
    "# Mel Spectrograms are not directly used as a feature in this model\n",
    "# Mel Spectrograms are used in calculating MFCCs, which are a higher-level representation of pitch transition\n",
    "# MFCCs work better - left the mel spectrogram function here in case anyone wants to experiment\n",
    "def feature_melspectrogram(\n",
    "    waveform, \n",
    "    sample_rate,\n",
    "    fft = 1024,\n",
    "    winlen = 512,\n",
    "    window='hamming',\n",
    "    hop=256,\n",
    "    mels=128,\n",
    "    ):\n",
    "    \n",
    "    # Produce the mel spectrogram for all STFT frames and get the mean of each column of the resulting matrix to create a feature array\n",
    "    # Using 8khz as upper frequency bound should be enough for most speech classification tasks\n",
    "    melspectrogram = librosa.feature.melspectrogram(\n",
    "        y=waveform, \n",
    "        sr=sample_rate, \n",
    "        n_fft=fft, \n",
    "        win_length=winlen, \n",
    "        window=window, \n",
    "        hop_length=hop, \n",
    "        n_mels=mels, \n",
    "        fmax=sample_rate/2)\n",
    "    \n",
    "    # convert from power (amplitude**2) to decibels\n",
    "    # necessary for network to learn - doesn't converge with raw power spectrograms \n",
    "    melspectrogram = librosa.power_to_db(melspectrogram, ref=np.max)\n",
    "    \n",
    "    return melspectrogram\n",
    "\n",
    "def feature_mfcc(\n",
    "    waveform, \n",
    "    sample_rate,\n",
    "    n_mfcc = 12,\n",
    "    fft = 1024,\n",
    "    winlen = 512,\n",
    "    window='hamming',\n",
    "    #hop=256, # increases # of time steps; was not helpful\n",
    "    mels=128\n",
    "    ):\n",
    "\n",
    "    # Compute the MFCCs for all STFT frames \n",
    "    # 40 mel filterbanks (n_mfcc) = 40 coefficients\n",
    "    mfc_coefficients=librosa.feature.mfcc(\n",
    "        y=waveform, \n",
    "        sr=sample_rate, \n",
    "        n_mfcc=n_mfcc,\n",
    "        n_fft=fft, \n",
    "        win_length=winlen, \n",
    "        window=window, \n",
    "        #hop_length=hop, \n",
    "        n_mels=mels, \n",
    "        fmax=sample_rate/2\n",
    "        ) \n",
    "\n",
    "    return np.mean(mfc_coefficients.T,axis=0)\n",
    "\n",
    "def get_features(waveforms, features, samplerate):\n",
    "\n",
    "    # initialize counter to track progress\n",
    "    file_count = 0\n",
    "\n",
    "    # process each waveform individually to get its MFCCs\n",
    "    for waveform in waveforms:\n",
    "        mfccs = feature_mfcc(waveform, sample_rate)\n",
    "        features.append(mfccs)\n",
    "        file_count += 1\n",
    "        # print progress \n",
    "        print('\\r'+f' Processed {file_count}/{len(waveforms)} waveforms',end='')\n",
    "    \n",
    "    # return all features from list of waveforms\n",
    "    return features\n",
    "\n",
    "def get_waveforms(file):\n",
    "    \n",
    "    # load an individual sample audio file\n",
    "    # read the full 3 seconds of the file, cut off the first 0.5s of silence; native sample rate = 48k\n",
    "    # don't need to store the sample rate that librosa.load returns\n",
    "    waveform, _ = librosa.load(file, duration=3, offset=0.5, sr=sample_rate)\n",
    "    \n",
    "    # make sure waveform vectors are homogenous by defining explicitly\n",
    "    waveform_homo = np.zeros((int(sample_rate*3,)))\n",
    "    waveform_homo[:len(waveform)] = waveform\n",
    "    \n",
    "    # return a single file's waveform                                      \n",
    "    return waveform_homo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c66dce04-b0b9-4485-a399-82b16f24e3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def awgn_augmentation(waveform, multiples=2, bits=16, snr_min=15, snr_max=30): \n",
    "    \n",
    "    # get length of waveform (should be 3*48k = 144k)\n",
    "    wave_len = len(waveform)\n",
    "    \n",
    "    # Generate normally distributed (Gaussian) noises\n",
    "    # one for each waveform and multiple (i.e. wave_len*multiples noises)\n",
    "    noise = np.random.normal(size=(multiples, wave_len))\n",
    "    \n",
    "    # Normalize waveform and noise\n",
    "    norm_constant = 2.0**(bits-1)\n",
    "    norm_wave = waveform / norm_constant\n",
    "    norm_noise = noise / norm_constant\n",
    "    \n",
    "    # Compute power of waveform and power of noise\n",
    "    signal_power = np.sum(norm_wave ** 2) / wave_len\n",
    "    noise_power = np.sum(norm_noise ** 2, axis=1) / wave_len\n",
    "    \n",
    "    # Choose random SNR in decibels in range [15,30]\n",
    "    snr = np.random.randint(snr_min, snr_max)\n",
    "    \n",
    "    # Apply whitening transformation: make the Gaussian noise into Gaussian white noise\n",
    "    # Compute the covariance matrix used to whiten each noise \n",
    "    # actual SNR = signal/noise (power)\n",
    "    # actual noise power = 10**(-snr/10)\n",
    "    covariance = np.sqrt((signal_power / noise_power) * 10 ** (- snr / 10))\n",
    "    # Get covariance matrix with dim: (144000, 2) so we can transform 2 noises: dim (2, 144000)\n",
    "    covariance = np.ones((wave_len, multiples)) * covariance\n",
    "\n",
    "    # Since covariance and noise are arrays, * is the haddamard product \n",
    "    # Take Haddamard product of covariance and noise to generate white noise\n",
    "    multiple_augmented_waveforms = waveform + covariance.T * noise\n",
    "    \n",
    "    return multiple_augmented_waveforms\n",
    "\n",
    "def augment_waveforms(waveforms, features, emotions, multiples,n_mfcc = 12):\n",
    "    # keep track of how many waveforms we've processed so we can add correct emotion label in the same order\n",
    "    emotion_count = 0\n",
    "    # keep track of how many augmented samples we've added\n",
    "    added_count = 0\n",
    "    # convert emotion array to list for more efficient appending\n",
    "    emotions = emotions.tolist()\n",
    "    # Saving augmented waveforms\n",
    "    lst = []\n",
    "    epsilon = 0.01\n",
    "\n",
    "    for waveform in waveforms:\n",
    "\n",
    "        # Generate 2 augmented multiples of the dataset, i.e. 1440 native + 1440*2 noisy = 4320 samples total\n",
    "        augmented_waveforms = awgn_augmentation(waveform, multiples=multiples)\n",
    "\n",
    "        # compute spectrogram for each of 2 augmented waveforms\n",
    "        for augmented_waveform in augmented_waveforms:\n",
    "\n",
    "            # Compute MFCCs over augmented waveforms\n",
    "            # original\n",
    "            augmented_mfcc = feature_mfcc(augmented_waveform, sample_rate=sample_rate, n_mfcc = n_mfcc)  \n",
    "\n",
    "            # append the augmented spectrogram to the rest of the native data\n",
    "            features.append(augmented_mfcc)\n",
    "            emotions.append(emotions[emotion_count])\n",
    "\n",
    "            # keep track of new augmented samples\n",
    "            added_count += 1\n",
    "\n",
    "            # check progress\n",
    "            print('\\r'+f'Processed {emotion_count + 1}/{len(waveforms)} waveforms for {added_count}/{len(waveforms)*multiples} new augmented samples',end='')\n",
    "            \n",
    "            ######################################################\n",
    "            ### Saving the augmented waveforms\n",
    "            ######################################################\n",
    "\n",
    "            waveform_homo = np.zeros((int(sample_rate*3,)))\n",
    "            waveform_homo[:len(augmented_waveform )] = augmented_waveform \n",
    "\n",
    "            energy = Audio_Energy(waveform_homo)\n",
    "            zero_cross =  Zero_Crossing(waveform_homo+epsilon)\n",
    "            spectral_centroids = Spectral_Centroids(waveform_homo+epsilon,sample_rate)\n",
    "            # La lista tiene 3 vectores de caracteristicas por elemento\n",
    "            arr = energy, zero_cross, spectral_centroids\n",
    "            lst.append(arr)\n",
    "            \n",
    "            \n",
    "        # keep track of the emotion labels to append in order\n",
    "        emotion_count += 1\n",
    "        \n",
    "        # store augmented waveforms to check their shape\n",
    "        #augmented_waveforms_temp.append(augmented_waveforms)\n",
    "    \n",
    "    return features, emotions,lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0451964-9ed6-4baa-8261-4dabb5d837b4",
   "metadata": {},
   "source": [
    "### Loading the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ac0c63b-cbbe-40e9-ab6d-c9ea7f1fe242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Audio Files\n",
      "1440\n",
      "--- Data loaded. Loading time: 191.76410245895386 seconds ---\n"
     ]
    }
   ],
   "source": [
    "big_model, small_model, big_model_log,small_model_log,audio_lengths,wave_forms, lst = creating_info_table(root_path+'/'+data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4843cf9a-1466-444b-8e0f-683ed8348205",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a29b0f5b-e390-4d45-9407-715275f815c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xb, yb = zip(*big_model)\n",
    "Xb = np.asarray(Xb)\n",
    "yb = np.asarray(yb)\n",
    "\n",
    "Xs, ys = zip(*small_model)\n",
    "Xs = np.asarray(Xs)\n",
    "ys = np.asarray(ys)\n",
    "\n",
    "Xbl, ybl = zip(*big_model_log)\n",
    "Xbl = np.asarray(Xbl)\n",
    "ybl = np.asarray(ybl)\n",
    "\n",
    "Xsl, ysl = zip(*small_model_log)\n",
    "Xsl = np.asarray(Xsl)\n",
    "ysl = np.asarray(ysl)\n",
    "\n",
    "wave_forms = np.asarray(wave_forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "354b5639-9fa7-4b71-a402-2fe0b155c45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'processed_data/mfccs_big_and_small_48.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6585bf14-5891-4de8-b99c-14810d25f172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features and labels saved to processed_data/mfccs_big_and_small_48.npy\n"
     ]
    }
   ],
   "source": [
    "# open file in write mode and write data\n",
    "with open(filename, 'wb') as f:\n",
    "    np.save(f, Xb)\n",
    "    np.save(f, yb)\n",
    "    np.save(f, Xs)\n",
    "    np.save(f, ys)\n",
    "    np.save(f, Xbl)\n",
    "    np.save(f, ybl)\n",
    "    np.save(f, Xsl)\n",
    "    np.save(f, ysl)\n",
    "    np.save(f,wave_forms)\n",
    "    \n",
    "print(f'Features and labels saved to {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d9324c9-ecfe-45b9-a8ee-197ccfe122ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xb:(1440, 40), yb:(1440,)\n",
      "Xs:(1440, 12), ys:(1440,)\n",
      "Xb:(1440, 40), yb:(1440,)\n",
      "Xs:(1440, 12), ys:(1440,)\n",
      "Wave Forms:(1440, 144000)\n"
     ]
    }
   ],
   "source": [
    "# Check the dimensions of the saved data\n",
    "print(f'Xb:{Xb.shape}, yb:{yb.shape}')\n",
    "print(f'Xs:{Xs.shape}, ys:{ys.shape}')\n",
    "print(f'Xb:{Xbl.shape}, yb:{ybl.shape}')\n",
    "print(f'Xs:{Xsl.shape}, ys:{ysl.shape}')\n",
    "print(f'Wave Forms:{wave_forms.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc34a545-4b80-48fd-8135-7d710623f3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xb:(1440, 40), yb:(1440,)\n",
      "Xs:(1440, 12), ys:(1440,)\n",
      "Xb:(1440, 40), yb:(1440,)\n",
      "Xs:(1440, 12), ys:(1440,)\n"
     ]
    }
   ],
   "source": [
    "# open file in read mode and read data \n",
    "with open(filename, 'rb') as f:\n",
    "    Xb = np.load(f)\n",
    "    yb = np.load(f)\n",
    "    Xs = np.load(f)\n",
    "    ys = np.load(f)\n",
    "    Xbl = np.load(f)\n",
    "    ybl = np.load(f)\n",
    "    Xsl = np.load(f)\n",
    "    ysl = np.load(f)\n",
    "# Check that we've recovered the right data\n",
    "print(f'Xb:{Xb.shape}, yb:{yb.shape}')\n",
    "print(f'Xs:{Xs.shape}, ys:{ys.shape}')\n",
    "print(f'Xb:{Xbl.shape}, yb:{ybl.shape}')\n",
    "print(f'Xs:{Xsl.shape}, ys:{ysl.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f68d3fec-238d-4e4d-82da-e227d75acffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving wave forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2f3acfe-842f-4d2a-b3eb-86bede48c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../processed_data/waveforms_48.npy'\n",
    "# open file in write mode and write data\n",
    "with open(filename, 'wb') as f:\n",
    "    np.save(f, wave_forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5204afb-9f46-474f-8b21-3443bcb26947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "267710bc-346f-43ed-9d0c-b4bcfbb0a651",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_energy, zero_cross, spectral_centroid = zip(*lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd28cfc7-f681-4bb3-966d-140f70c9f9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features and labels saved to processed_data/more_features_48.npy\n"
     ]
    }
   ],
   "source": [
    "filename = '../processed_data/more_features_48.npy'\n",
    "# open file in write mode and write data\n",
    "with open(filename, 'wb') as f:\n",
    "    np.save(f, rms_energy)\n",
    "    np.save(f, zero_cross)\n",
    "    np.save(f, spectral_centroid )\n",
    "\n",
    "print(f'Features and labels saved to {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cba2e416-e7ff-4189-a14c-ef941e3159ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_energy_original = np.asarray(rms_energy).copy()\n",
    "zero_cross_original =  np.asarray(zero_cross).copy()\n",
    "\n",
    "# Decidí no utilizar el centroide del espectro por ser redundante en relacion al mel spectrogram!\n",
    "spectral_centroid_original = np.asarray(spectral_centroid).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdd1f5b-c7a0-4d37-9f2a-ff0d180aa706",
   "metadata": {},
   "source": [
    "### Data augmentation and merging the original data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ace29db6-bb1a-43e4-8c17-fb0003e7f671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original waveforms augmented:\n",
      "Processed 1440/1440 waveforms for 4320/4320 new augmented samples"
     ]
    }
   ],
   "source": [
    "features_augmented_12 = []\n",
    "\n",
    "multiples = 3\n",
    "\n",
    "print('Original waveforms augmented:')\n",
    "features_augmented_12 , y_augmented_12, lst_augmented_12 = augment_waveforms(wave_forms,features_augmented_12, yb, multiples, n_mfcc = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f514f904-c489-4b65-bf00-c4b9add5413d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original waveforms augmented:\n",
      "Processed 1440/1440 waveforms for 4320/4320 new augmented samples"
     ]
    }
   ],
   "source": [
    "print('Original waveforms augmented:')\n",
    "features_augmented_40 = []\n",
    "features_augmented_40 , y_augmented_40, lst_augmented_40 = augment_waveforms(wave_forms,features_augmented_40, yb, multiples, n_mfcc = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a3243d-3236-4cee-aee7-73510223c2c3",
   "metadata": {},
   "source": [
    "### Merging the data into different test groups\n",
    "\n",
    "For example:\n",
    "    \n",
    "    - using 12 bins for the mel-spectrogram with data augmentation\n",
    "    \n",
    "    - using 40 bins for the mel-spectrogram with data augmentation\n",
    "    \n",
    "    - using 12 bins for the mel-spectrogram with data augmentation + other features\n",
    "    \n",
    "    - using 40 bins for the mel-spectrogram with data augmentation + other features\n",
    "\n",
    "Let us begin with the 12 bin group!: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0acc1649-86a8-444d-835f-c106a592a458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4320, 12)\n",
      "(5760,)\n",
      "(4320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(features_augmented_12).shape)\n",
    "print(np.asarray(y_augmented_12).shape)  # ya están unidos, el problema es debido a que salvo antes!\n",
    "print(np.asarray(lst_augmented_12).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1261e3-24da-47ec-8ce6-c992b2a58774",
   "metadata": {},
   "source": [
    "Finally, merging: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32e68a83-2cff-41ba-99ba-807f4585c4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "F12 = np.vstack((Xs,np.asarray(features_augmented_12)))\n",
    "F40 = np.vstack((Xb,np.asarray(features_augmented_40)))\n",
    "Y = np.asarray(y_augmented_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca433f87-1e1a-4fd4-b806-1194c1181d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5760, 12)\n",
      "(5760, 40)\n",
      "(5760,)\n"
     ]
    }
   ],
   "source": [
    "print(F12.shape)\n",
    "print(F40.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24800cc4-9bd7-412e-882e-ade3a3d9f486",
   "metadata": {},
   "source": [
    "The following matrices are the definitive features. They will be used to find the better architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58e4b693-9d5f-4b92-8d8a-cc3cb8a7aa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../processed_data/MFCCs_AUGMENTED_48.npy'\n",
    "# open file in write mode and write data\n",
    "with open(filename, 'wb') as f:\n",
    "    np.save(f, F12)\n",
    "    np.save(f, F40)\n",
    "    np.save(f, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2464d5e5-b623-4329-b678-6bd203389983",
   "metadata": {},
   "source": [
    "Both, 12 and 40 groups, have the same time and frequency features (I'm not setting the spectrum for this features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0763f791-c77d-484b-ab63-6100438b85aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_energy, zero_cross, spectral_centroid= zip(*lst_augmented_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e55bc131-7e02-4d83-8766-d9bdc54cb56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4320, 1, 563)\n",
      "(4320, 1, 282)\n",
      "(4320, 282)\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(rms_energy).shape)\n",
    "print(np.asarray(zero_cross).shape)  # ya están unidos, el problema es debido a que salvo antes!\n",
    "print(np.asarray(spectral_centroid).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "759dc86a-142c-450e-800a-b3be0b918eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 1, 563)\n",
      "(1440, 1, 282)\n",
      "(1440, 282)\n"
     ]
    }
   ],
   "source": [
    "print(rms_energy_original.shape)\n",
    "print(zero_cross_original.shape)  # ya están unidos, el problema es debido a que salvo antes!\n",
    "print(spectral_centroid_original.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104bcb17-ff0a-4b97-8e4a-9b0c5cc13d16",
   "metadata": {},
   "source": [
    "Finally, merging! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac65211a-5bd1-47d8-9f48-9b73af03a25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_energy = np.reshape(np.asarray(rms_energy),(np.asarray(rms_energy).shape[0],np.asarray(rms_energy).shape[2]))\n",
    "zero_cross = np.reshape(np.asarray(zero_cross),(np.asarray(zero_cross).shape[0],np.asarray(zero_cross).shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07a28a9c-cdbf-414a-b05e-0e93dca60740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4320, 563)\n",
      "(4320, 282)\n"
     ]
    }
   ],
   "source": [
    "print(rms_energy.shape)\n",
    "print(zero_cross.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca3dced1-c91b-4f89-a106-ab8c66dbbc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_energy_original = np.reshape(np.asarray(rms_energy_original ),(np.asarray(rms_energy_original ).shape[0],np.asarray(rms_energy_original ).shape[2]))\n",
    "zero_cross_original  = np.reshape(np.asarray(zero_cross_original ),(np.asarray(zero_cross_original ).shape[0],np.asarray(zero_cross_original ).shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee31cdd3-e6a1-4179-b5f8-20520d1eb636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 563)\n",
      "(1440, 282)\n"
     ]
    }
   ],
   "source": [
    "print(rms_energy_original.shape)\n",
    "print(zero_cross_original.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c041e818-1f04-47ed-a2d5-d90edd34f32a",
   "metadata": {},
   "source": [
    "The first 1440 examples are the originals, then the augmented ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f267cf98-2295-4614-b58d-24cff2d0e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = np.vstack((rms_energy_original,rms_energy))\n",
    "Z = np.vstack((zero_cross_original,zero_cross))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8eceeb39-179c-4704-b622-8d89feade0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5760, 563)\n",
      "(5760, 282)\n"
     ]
    }
   ],
   "source": [
    "print(E.shape)\n",
    "print(Z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "701e3ab4-fc6d-4836-9fa3-3e3542f556f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../processed_data/ZE_48.npy'\n",
    "# open file in write mode and write data\n",
    "with open(filename, 'wb') as f:\n",
    "    np.save(f, Z)\n",
    "    np.save(f, E)\n",
    "    np.save(f, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3b5015-e134-4e3f-9549-beda0be18fa7",
   "metadata": {},
   "source": [
    "Merging all the features in one thing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ecddacfe-34ad-4b0d-802c-ceb7ef045bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5760"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1440 + multiples*1440"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced73bf8-047c-43b4-9bab-e251e20a4977",
   "metadata": {},
   "source": [
    "12 features and spectrum!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbb4bcf4-fe81-493e-9ff8-9d1856ac1729",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL12_48 = []\n",
    "for i in range(1440 + multiples*1440):\n",
    "    ALL12_48.append(np.hstack((E[i,:],Z[i,:],F12[i,:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "530fbae8-61d0-446c-a380-5b5a16fe0d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5760, 857)\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(ALL12_48).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9448437-b0a9-4b97-b06a-9c6269a2dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../processed_data/ALL12_48.npy'\n",
    "# open file in write mode and write data\n",
    "with open(filename, 'wb') as f:\n",
    "    np.save(f, ALL12_48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a2a2cf9-89b8-4a29-8d5c-2c2b1db5a0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL40_48 = []\n",
    "for i in range(1440 + multiples*1440):\n",
    "    ALL40_48.append(np.hstack((E[i,:],Z[i,:],F40[i,:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5db4b8e7-1ed7-48b4-891e-fe8101e03f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../processed_data/ALL40_48.npy'\n",
    "# open file in write mode and write data\n",
    "with open(filename, 'wb') as f:\n",
    "    np.save(f, ALL40_48)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf09b35-0865-46de-bec0-f2f42afc65be",
   "metadata": {},
   "source": [
    "# Preprocesamiento que falta !!!\n",
    "\n",
    "Terminé de procesar a 48KHz todas las combinaciones de 12,40 + otras caracteristicas! :D\n",
    "\n",
    "Después tengo que hacer lo mismo para 22050 Hz y también para 16000 Hz, 8000 Hz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd8626e5-637e-46ae-a6ec-79b771a20721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Audio Files\n",
      "1440\n",
      "--- Data loaded. Loading time: 165.31732773780823 seconds ---\n"
     ]
    }
   ],
   "source": [
    "big_model, small_model, big_model_log,small_model_log,audio_lengths,wave_forms, lst = creating_info_table(root_path+'/'+data_path, 22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ffaff92-54ec-4287-9d36-73bcbb24ade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xb, yb = zip(*big_model)\n",
    "Xb = np.asarray(Xb)\n",
    "yb = np.asarray(yb)\n",
    "\n",
    "Xs, ys = zip(*small_model)\n",
    "Xs = np.asarray(Xs)\n",
    "ys = np.asarray(ys)\n",
    "\n",
    "Xbl, ybl = zip(*big_model_log)\n",
    "Xbl = np.asarray(Xbl)\n",
    "ybl = np.asarray(ybl)\n",
    "\n",
    "Xsl, ysl = zip(*small_model_log)\n",
    "Xsl = np.asarray(Xsl)\n",
    "ysl = np.asarray(ysl)\n",
    "\n",
    "wave_forms = np.asarray(wave_forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93f8f6eb-8d64-493a-bb6e-61418b545f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../processed_data/mfccs_big_and_small_22.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28cee155-c36a-4685-8ad6-1476233538d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features and labels saved to processed_data/mfccs_big_and_small_22.npy\n"
     ]
    }
   ],
   "source": [
    "# open file in write mode and write data\n",
    "with open(filename, 'wb') as f:\n",
    "    np.save(f, Xb)\n",
    "    np.save(f, yb)\n",
    "    np.save(f, Xs)\n",
    "    np.save(f, ys)\n",
    "    np.save(f, Xbl)\n",
    "    np.save(f, ybl)\n",
    "    np.save(f, Xsl)\n",
    "    np.save(f, ysl)\n",
    "    np.save(f,wave_forms)\n",
    "    \n",
    "print(f'Features and labels saved to {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f4174f14-ab76-4618-9984-932465ba9a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xb:(1440, 40), yb:(1440,)\n",
      "Xs:(1440, 12), ys:(1440,)\n",
      "Xb:(1440, 40), yb:(1440,)\n",
      "Xs:(1440, 12), ys:(1440,)\n",
      "Wave Forms:(1440, 66150)\n"
     ]
    }
   ],
   "source": [
    "# Check the dimensions of the saved data\n",
    "print(f'Xb:{Xb.shape}, yb:{yb.shape}')\n",
    "print(f'Xs:{Xs.shape}, ys:{ys.shape}')\n",
    "print(f'Xb:{Xbl.shape}, yb:{ybl.shape}')\n",
    "print(f'Xs:{Xsl.shape}, ys:{ysl.shape}')\n",
    "print(f'Wave Forms:{wave_forms.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "956c1549-53ba-4d29-9452-112c3a96cdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../processed_data/waveforms_22.npy'\n",
    "# open file in write mode and write data\n",
    "with open(filename, 'wb') as f:\n",
    "    np.save(f, wave_forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e0bad9d9-aba4-47ce-a89f-ea30e3a971de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original waveforms augmented:\n",
      "Processed 1440/1440 waveforms for 4320/4320 new augmented samples"
     ]
    }
   ],
   "source": [
    "features_augmented_12 = []\n",
    "\n",
    "multiples = 3\n",
    "\n",
    "print('Original waveforms augmented:')\n",
    "features_augmented_12 , y_augmented_12, lst_augmented_12 = augment_waveforms(wave_forms,features_augmented_12, yb, multiples, n_mfcc = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52dc97b7-472a-4ba2-9ffa-c683fea37cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original waveforms augmented:\n",
      "Processed 1440/1440 waveforms for 4320/4320 new augmented samples"
     ]
    }
   ],
   "source": [
    "print('Original waveforms augmented:')\n",
    "features_augmented_40 = []\n",
    "features_augmented_40 , y_augmented_40, lst_augmented_40 = augment_waveforms(wave_forms,features_augmented_40, yb, multiples, n_mfcc = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6eb9e12a-5cc9-430d-88b2-03f5a62170d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "F12 = np.vstack((Xs,np.asarray(features_augmented_12)))\n",
    "F40 = np.vstack((Xb,np.asarray(features_augmented_40)))\n",
    "Y = np.asarray(y_augmented_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "86daea59-1b8b-42d3-939a-e0397a4e6947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5760, 12)\n",
      "(5760, 40)\n",
      "(5760,)\n"
     ]
    }
   ],
   "source": [
    "print(F12.shape)\n",
    "print(F40.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c2e79756-6b44-418e-a972-e268156a3d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../processed_data/MFCCs_AUGMENTED_22.npy'\n",
    "# open file in write mode and write data\n",
    "with open(filename, 'wb') as f:\n",
    "    np.save(f, F12)\n",
    "    np.save(f, F40)\n",
    "    np.save(f, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2dcd8b0c-9334-4971-b8f7-2ff69453a8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../processed_data/more_features_48.npy'\n",
    "# open file in write mode and write data\n",
    "with open(filename, 'rb') as f:\n",
    "    rms_energy = np.load(f)\n",
    "    zero_cross = np.load(f)\n",
    "    spectral_centroid = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b4bb3538-163c-4cf7-9c76-9efcf93e1cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_energy_original = np.asarray(rms_energy).copy()\n",
    "zero_cross_original =  np.asarray(zero_cross).copy()\n",
    "spectral_centroid_original = np.asarray(spectral_centroid).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "48538057-cb71-429c-81e9-a9a9f95145c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_energy_original = np.reshape(np.asarray(rms_energy_original ),(np.asarray(rms_energy_original ).shape[0],np.asarray(rms_energy_original ).shape[2]))\n",
    "zero_cross_original  = np.reshape(np.asarray(zero_cross_original ),(np.asarray(zero_cross_original ).shape[0],np.asarray(zero_cross_original ).shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "78e6cb5d-a619-4dd5-9f17-f1d79a861e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_energy, zero_cross, spectral_centroid= zip(*lst_augmented_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "438469f8-f322-4dcc-ab0e-4f55a29dd206",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_energy = np.reshape(np.asarray(rms_energy),(np.asarray(rms_energy).shape[0],np.asarray(rms_energy).shape[2]))\n",
    "zero_cross = np.reshape(np.asarray(zero_cross),(np.asarray(zero_cross).shape[0],np.asarray(zero_cross).shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e7fd964d-8966-446a-814c-cbc4074bde8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 563)\n",
      "(1440, 282)\n"
     ]
    }
   ],
   "source": [
    "print(rms_energy_original.shape)\n",
    "print(zero_cross_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3a79554c-6aef-4cdd-af05-54358e72e007",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = np.vstack((rms_energy_original,rms_energy))\n",
    "Z = np.vstack((zero_cross_original,zero_cross))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "137fc8e9-58ca-4cfa-b329-352c058a9712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5760, 563)\n",
      "(5760, 282)\n"
     ]
    }
   ],
   "source": [
    "print(E.shape)\n",
    "print(Z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6ed28ef8-945c-4dd9-b10f-11c10a83bb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../processed_data/ZE_22.npy'\n",
    "# open file in write mode and write data\n",
    "with open(filename, 'wb') as f:\n",
    "    np.save(f, Z)\n",
    "    np.save(f, E)\n",
    "    np.save(f, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bb528906-fafe-49b6-9230-2f049d515860",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL12_22 = []\n",
    "for i in range(1440 + multiples*1440):\n",
    "    ALL12_22.append(np.hstack((E[i,:],Z[i,:],F12[i,:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5f54359b-4b79-4a18-bb22-e4c9b50804f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../processed_data/ALL12_22.npy'\n",
    "# open file in write mode and write data\n",
    "with open(filename, 'wb') as f:\n",
    "    np.save(f, ALL12_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ec409b54-8fde-404b-8e60-6d659026c98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL40_22 = []\n",
    "for i in range(1440 + multiples*1440):\n",
    "    ALL40_22.append(np.hstack((E[i,:],Z[i,:],F40[i,:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "31ae8d93-b332-48aa-928b-278d820e5ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../processed_data/ALL40_22.npy'\n",
    "# open file in write mode and write data\n",
    "with open(filename, 'wb') as f:\n",
    "    np.save(f, ALL40_22)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
